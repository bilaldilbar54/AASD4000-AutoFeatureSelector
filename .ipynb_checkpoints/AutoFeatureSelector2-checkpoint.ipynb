{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd2b2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to your dataset file: /Users/bilaldilbar/Documents/GeorgeBrown/Sem1/AASD4000/Assignments/Task 7/Fifa19 Dataset/fifa19.csv\n",
      "Enter feature selection methods from chi2, rfe, logreg, lgbm (comma-separated): chi2,rfe\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def embedded_lgbm_selector(X, y, num_feats):\n",
    "    lgbmc = LGBMClassifier(n_estimators=500,\n",
    "                           learning_rate=0.05,\n",
    "                           num_leaves=32,\n",
    "                           colsample_bytree=0.2,\n",
    "                           reg_alpha=3,\n",
    "                           reg_lambda=1,\n",
    "                           min_split_gain=0.01,\n",
    "                           min_child_weight=40\n",
    "                          )\n",
    "    embedded_lgbm_selector = SelectFromModel(lgbmc,\n",
    "                                             max_features=num_feats\n",
    "                                            )\n",
    "    embedded_lgbm_selector = embedded_lgbm_selector.fit(X, y)\n",
    "    embedded_lgbm_support = embedded_lgbm_selector.get_support()\n",
    "    embedded_lgbm_feature = X.loc[:, embedded_lgbm_support].columns.tolist()\n",
    "    return embedded_lgbm_support, embedded_lgbm_feature\n",
    "\n",
    "def embedded_rf_selector(X, y, num_feats):\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    embedded_rf_selector = SelectFromModel(rf, \n",
    "                                           max_features=num_feats\n",
    "                                          )\n",
    "    embedded_rf_selector = embedded_rf_selector.fit(X, y)\n",
    "    embedded_rf_support = embedded_rf_selector.get_support()\n",
    "    embedded_rf_feature = X.loc[:, embedded_rf_support].columns.tolist()\n",
    "    return embedded_rf_support, embedded_rf_feature\n",
    "\n",
    "def embedded_log_reg_selector(X, y, num_feats):\n",
    "    logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "    embedded_lr_selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear', max_iter=50000), max_features=num_feats)\n",
    "    embedded_lr_selector = embedded_lr_selector.fit(X, y)\n",
    "    embedded_lr_support = embedded_lr_selector.get_support()\n",
    "    embedded_lr_feature = X.loc[:, embedded_lr_support].columns.tolist()\n",
    "    return embedded_lr_support, embedded_lr_feature\n",
    "\n",
    "def rfe_selector(X, y, num_feats):\n",
    "    rf = RandomForestClassifier()\n",
    "    rfe = RFE(estimator=rf, \n",
    "              n_features_to_select=num_feats,\n",
    "              step=1,\n",
    "              verbose=5\n",
    "             )\n",
    "    rfe = rfe.fit(X, y)\n",
    "    rfe_support = rfe.get_support()\n",
    "    rfe_feature = X.loc[:, rfe_support].columns.tolist()\n",
    "    return rfe_support, rfe_feature\n",
    "\n",
    "def chi_squared_selector(X, y, num_feats):\n",
    "    X_norm = MinMaxScaler().fit_transform(X)\n",
    "    chi_selector = SelectKBest(chi2, k=num_feats)\n",
    "    chi_selector.fit(X_norm, y)\n",
    "    chi_support = chi_selector.get_support()\n",
    "    chi_feature = X.loc[:, chi_support].columns.tolist()\n",
    "    return chi_support, chi_feature\n",
    "\n",
    "def cor_selector(X, y, num_feats):\n",
    "    correlations = X.corrwith(y).abs()\n",
    "    cor_feature = correlations.nlargest(num_feats).index.tolist()\n",
    "    cor_support = [True if feature in cor_feature else False for feature in X.columns]\n",
    "    \n",
    "    return cor_support, cor_feature\n",
    "\n",
    "def preprocess_dataset(dataset_path):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Separate features (X) and target variable (y)\n",
    "    numcols = ['Overall', 'Crossing', 'Finishing', 'ShortPassing', 'Dribbling', 'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility', 'Stamina', 'Volleys', 'FKAccuracy', 'Reactions', 'Balance', 'ShotPower', 'Strength', 'LongShots', 'Aggression', 'Interceptions']\n",
    "    catcols = ['Preferred Foot', 'Position', 'Body Type', 'Nationality', 'Weak Foot']\n",
    "    features = numcols + catcols\n",
    "    df = df[features]\n",
    "    df = pd.concat([df[numcols], pd.get_dummies(df[catcols])], axis=1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Define the target variable\n",
    "    y = df['Overall'] >= 87\n",
    "\n",
    "    # Remove the target variable from the features\n",
    "    X = df.drop(columns=['Overall'])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def feature_selection(X, y, method, num_feats):\n",
    "    if method == 'chi2':\n",
    "        support, selected_features = chi_squared_selector(X, y, num_feats)\n",
    "    elif method == 'rfe':\n",
    "        support, selected_features = rfe_selector(X, y, num_feats)\n",
    "    elif method == 'logreg':\n",
    "        support, selected_features = embedded_log_reg_selector(X, y, num_feats)\n",
    "    elif method == 'lgbm':\n",
    "        support, selected_features = embedded_lgbm_selector(X, y, num_feats)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection method.\")\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = input(\"Enter the path to your dataset file: \")\n",
    "    available_methods = ['chi2', 'rfe', 'logreg', 'lgbm']\n",
    "    selected_methods = input(f\"Enter feature selection methods from {', '.join(available_methods)} (comma-separated): \").split(',')\n",
    "\n",
    "    X, y = preprocess_dataset(dataset_path)\n",
    "    num_feats = 30\n",
    "\n",
    "    selected_features = set()  # Use a set to collect unique selected features\n",
    "\n",
    "    for method in selected_methods:\n",
    "        selected_features.update(feature_selection(X, y, method, num_feats))\n",
    "\n",
    "    selected_features = list(selected_features)  # Convert the set back to a list\n",
    "\n",
    "    print(f\"Selected features: {', '.join(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ae100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c4333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
