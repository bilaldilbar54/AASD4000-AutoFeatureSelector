{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23867155",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to your dataset file: /Users/bilaldilbar/Documents/GeorgeBrown/Sem1/AASD4000/Assignments/Task 7/Fifa19 Dataset/fifa19.csv\n",
      "Enter feature selection methods from chi2, rfe, logreg, lgbm (comma-separated): chi2,rfe\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def embedded_lgbm_selector(X, y, num_feats):\n",
    "    lgbmc = LGBMClassifier(n_estimators=500,\n",
    "                           learning_rate=0.05,\n",
    "                           num_leaves=32,\n",
    "                           colsample_bytree=0.2,\n",
    "                           reg_alpha=3,\n",
    "                           reg_lambda=1,\n",
    "                           min_split_gain=0.01,\n",
    "                           min_child_weight=40\n",
    "                          )\n",
    "    embedded_lgbm_selector = SelectFromModel(lgbmc,\n",
    "                                             max_features=num_feats\n",
    "                                            )\n",
    "    embedded_lgbm_selector = embedded_lgbm_selector.fit(X, y)\n",
    "    embedded_lgbm_support = embedded_lgbm_selector.get_support()\n",
    "    embedded_lgbm_feature = X.loc[:, embedded_lgbm_support].columns.tolist()\n",
    "    return embedded_lgbm_support, embedded_lgbm_feature\n",
    "\n",
    "def embedded_rf_selector(X, y, num_feats):\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    embedded_rf_selector = SelectFromModel(rf, \n",
    "                                           max_features=num_feats\n",
    "                                          )\n",
    "    embedded_rf_selector = embedded_rf_selector.fit(X, y)\n",
    "    embedded_rf_support = embedded_rf_selector.get_support()\n",
    "    embedded_rf_feature = X.loc[:, embedded_rf_support].columns.tolist()\n",
    "    return embedded_rf_support, embedded_rf_feature\n",
    "\n",
    "def embedded_log_reg_selector(X, y, num_feats):\n",
    "    logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "    embedded_lr_selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear', max_iter=50000), max_features=num_feats)\n",
    "    embedded_lr_selector = embedded_lr_selector.fit(X, y)\n",
    "    embedded_lr_support = embedded_lr_selector.get_support()\n",
    "    embedded_lr_feature = X.loc[:, embedded_lr_support].columns.tolist()\n",
    "    return embedded_lr_support, embedded_lr_feature\n",
    "\n",
    "def rfe_selector(X, y, num_feats):\n",
    "    rf = RandomForestClassifier()\n",
    "    rfe = RFE(estimator=rf, \n",
    "              n_features_to_select=num_feats,\n",
    "              step=1,\n",
    "              verbose=5\n",
    "             )\n",
    "    rfe = rfe.fit(X, y)\n",
    "    rfe_support = rfe.get_support()\n",
    "    rfe_feature = X.loc[:, rfe_support].columns.tolist()\n",
    "    return rfe_support, rfe_feature\n",
    "\n",
    "def chi_squared_selector(X, y, num_feats):\n",
    "    X_norm = MinMaxScaler().fit_transform(X)\n",
    "    chi_selector = SelectKBest(chi2, k=num_feats)\n",
    "    chi_selector.fit(X_norm, y)\n",
    "    chi_support = chi_selector.get_support()\n",
    "    chi_feature = X.loc[:, chi_support].columns.tolist()\n",
    "    return chi_support, chi_feature\n",
    "\n",
    "def cor_selector(X, y, num_feats):\n",
    "    correlations = X.corrwith(y).abs()\n",
    "    cor_feature = correlations.nlargest(num_feats).index.tolist()\n",
    "    cor_support = [True if feature in cor_feature else False for feature in X.columns]\n",
    "    \n",
    "    return cor_support, cor_feature\n",
    "\n",
    "def preprocess_dataset(dataset_path):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Separate features (X) and target variable (y)\n",
    "    numcols = ['Overall', 'Crossing', 'Finishing', 'ShortPassing', 'Dribbling', 'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility', 'Stamina', 'Volleys', 'FKAccuracy', 'Reactions', 'Balance', 'ShotPower', 'Strength', 'LongShots', 'Aggression', 'Interceptions']\n",
    "    catcols = ['Preferred Foot', 'Position', 'Body Type', 'Nationality', 'Weak Foot']\n",
    "    features = numcols + catcols\n",
    "    df = df[features]\n",
    "    df = pd.concat([df[numcols], pd.get_dummies(df[catcols])], axis=1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Define the target variable\n",
    "    y = df['Overall'] >= 87\n",
    "\n",
    "    # Remove the target variable from the features\n",
    "    X = df.drop(columns=['Overall'])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def feature_selection(X, y, method, num_feats):\n",
    "    if method == 'chi2':\n",
    "        support, selected_features = chi_squared_selector(X, y, num_feats)\n",
    "    elif method == 'rfe':\n",
    "        support, selected_features = rfe_selector(X, y, num_feats)\n",
    "    elif method == 'logreg':\n",
    "        support, selected_features = embedded_log_reg_selector(X, y, num_feats)\n",
    "    elif method == 'lgbm':\n",
    "        support, selected_features = embedded_lgbm_selector(X, y, num_feats)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature selection method.\")\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = input(\"Enter the path to your dataset file: \")\n",
    "    available_methods = ['chi2', 'rfe', 'logreg', 'lgbm']\n",
    "    selected_methods = input(f\"Enter feature selection methods from {', '.join(available_methods)} (comma-separated): \").split(',')\n",
    "\n",
    "    X, y = preprocess_dataset(dataset_path)\n",
    "    num_feats = 30\n",
    "\n",
    "    selected_features = set()  # Use a set to collect unique selected features\n",
    "\n",
    "    for method in selected_methods:\n",
    "        selected_features.update(feature_selection(X, y, method, num_feats))\n",
    "\n",
    "    selected_features = list(selected_features)  # Convert the set back to a list\n",
    "\n",
    "    print(f\"Selected features: {', '.join(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2470bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45819790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
